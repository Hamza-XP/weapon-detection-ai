{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weapon Detection Model Training\n",
    "This notebook trains a TensorFlow object detection model using your custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "Install required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.12.0\n",
    "!pip install tensorflow-object-detection-api\n",
    "!pip install protobuf==3.20.3\n",
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "Parse XML annotations and create TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import dataset_util, label_map_util\n",
    "from collections import namedtuple\n",
    "\n",
    "# Define class labels based on your folders\n",
    "CLASSES = {\n",
    "    'gun': 1,\n",
    "    'knife': 2,\n",
    "    'hammer': 3,\n",
    "    'bat': 4,\n",
    "    'person': 5\n",
    "}\n",
    "\n",
    "def parse_xml(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    filename = root.find('filename').text\n",
    "    width = int(root.find('size/width').text)\n",
    "    height = int(root.find('size/height').text)\n",
    "\n",
    "    objects = []\n",
    "    for obj in root.findall('object'):\n",
    "        label = obj.find('name').text.lower()\n",
    "        if label == 'base ball bat':\n",
    "            label = 'bat'\n",
    "        bndbox = obj.find('bndbox')\n",
    "        xmin = int(bndbox.find('xmin').text)\n",
    "        ymin = int(bndbox.find('ymin').text)\n",
    "        xmax = int(bndbox.find('xmax').text)\n",
    "        ymax = int(bndbox.find('ymax').text)\n",
    "\n",
    "        objects.append({\n",
    "            'label': label,\n",
    "            'xmin': xmin,\n",
    "            'ymin': ymin,\n",
    "            'xmax': xmax,\n",
    "            'ymax': ymax\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        'filename': filename,\n",
    "        'width': width,\n",
    "        'height': height,\n",
    "        'objects': objects\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create TFRecords\n",
    "Convert dataset to TensorFlow format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_example(example, images_dir):\n",
    "    img_path = os.path.join(images_dir, example['filename'])\n",
    "    with tf.io.gfile.GFile(img_path, 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "\n",
    "    width = example['width']\n",
    "    height = example['height']\n",
    "    filename = example['filename'].encode('utf8')\n",
    "    image_format = b'jpg'\n",
    "\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for obj in example['objects']:\n",
    "        xmins.append(obj['xmin'] / width)\n",
    "        xmaxs.append(obj['xmax'] / width)\n",
    "        ymins.append(obj['ymin'] / height)\n",
    "        ymaxs.append(obj['ymax'] / height)\n",
    "        classes_text.append(obj['label'].encode('utf8'))\n",
    "        classes.append(CLASSES[obj['label']])\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write TFRecord files\n",
    "def generate_tfrecord_from_dataset(dataset_dir, output_path):\n",
    "    writer = tf.io.TFRecordWriter(output_path)\n",
    "\n",
    "    for class_folder in os.listdir(dataset_dir):\n",
    "        folder_path = os.path.join(dataset_dir, class_folder)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        for file in os.listdir(folder_path):\n",
    "            if not file.endswith(\".xml\"):\n",
    "                continue\n",
    "            xml_path = os.path.join(folder_path, file)\n",
    "            try:\n",
    "                annotation = parse_xml(xml_path)\n",
    "                tf_example = create_tf_example(annotation, folder_path)\n",
    "                writer.write(tf_example.SerializeToString())\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {xml_path}: {e}\")\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "# Example usage\n",
    "generate_tfrecords_from_dataset('images/train', 'annotations/train', 'train.record')\n",
    "generate_tfrecords_from_dataset('images/val', 'annotations/val', 'val.record')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p training\n",
    "label_map_content = \"\"\n",
    "for name, id in CLASSES.items():\n",
    "    label_map_content += f'item {{\\n  id: {id}\\n  name: \\\"{name}\\\"\\n}}\\n\\n'\n",
    "\n",
    "with open('training/label_map.pbtxt', 'w') as f:\n",
    "    f.write(label_map_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
    "!tar -xzf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
    "!mv ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the pipeline.config\n",
    "!sed -i \"s/num_classes: 90/num_classes: 5/g\" ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
    "!sed -i \"s|PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt|training/label_map.pbtxt|g\" ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
    "!sed -i \"s|PATH_TO_BE_CONFIGURED/train.record|train.record|g\" ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
    "!sed -i \"s|PATH_TO_BE_CONFIGURED/val.record|val.record|g\" ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m object_detection.model_main_tf2 \\\n",
    "    --pipeline_config_path=ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config \\\n",
    "    --model_dir=training/ \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps=10000 \\\n",
    "    --sample_1_of_n_eval_examples=1 \\\n",
    "    --num_eval_steps=500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m object_detection.exporter_main_v2 \\\n",
    "    --input_type image_tensor \\\n",
    "    --pipeline_config_path ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config \\\n",
    "    --trained_checkpoint_dir training/ \\\n",
    "    --output_directory inference_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Verify Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "# Load saved model\n",
    "model = tf.saved_model.load('inference_graph/saved_model')\n",
    "\n",
    "def detect_objects(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    input_tensor = tf.convert_to_tensor(image)\n",
    "    input_tensor = input_tensor[tf.newaxis,...]\n",
    "\n",
    "    detections = model(input_tensor)\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image,\n",
    "        detections['detection_boxes'][0].numpy(),\n",
    "        detections['detection_classes'][0].numpy().astype(int),\n",
    "        detections['detection_scores'][0].numpy(),\n",
    "        label_map_util.create_category_index_from_labelmap('training/label_map.pbtxt'),\n",
    "        use_normalized_coordinates=True,\n",
    "        max_boxes_to_draw=5,\n",
    "        min_score_thresh=0.5\n",
    "    )\n",
    "\n",
    "    cv2.imshow('Detection', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Test on a sample image\n",
    "detect_objects('test_images/image_401.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
